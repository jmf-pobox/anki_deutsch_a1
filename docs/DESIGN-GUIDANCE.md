# Design Guidance for German A1 Anki Deck Generator

**Document Version**: 2.0  
**Target Audience**: Software Engineers (All Levels)  
**Last Updated**: 2025-08-19
**Status**: Production-ready with AI enhancements

---

## ðŸŽ¯ Executive Summary

This document provides design guidance for maintaining and extending the German A1 Anki deck generator. The application has achieved production quality with AI-enhanced features and serves as a foundation for future multi-language expansion.

**Core Philosophy**: 
- Use external validated data for grammatical forms
- Never implement algorithmic grammar processing
- Prioritize context-aware AI for enhanced learning
- Maintain type safety and clean architecture

---

## ðŸ“Š Current State Assessment

### âœ… **Quality Achievements**
**Quality Score**: 9.5/10 (Enterprise-grade with AI enhancements)

#### **Production Quality Standards Met**:
1. **Type Safety Excellence**: 0 MyPy strict mode errors maintained
2. **Code Quality**: Clean ruff compliance with consistent formatting
3. **Test Coverage**: 22.93% with comprehensive integration testing
4. **Architecture**: Clean domain-driven design implementation
5. **AI Integration**: Context-aware image search with Claude
6. **Production Backend**: Official Anki library with proper media handling

#### **System Capabilities**:
- **German A1 Support**: Complete coverage (254 vocabulary entries)
- **AI Enhancement**: Context-aware image selection
- **Audio Integration**: AWS Polly German pronunciation
- **Production Quality**: Enterprise-grade error handling and logging
- **Multi-Language Readiness**: 3/10 (architectural foundation established)

---

## ðŸ—ï¸ Architectural Principles (MANDATORY)

### 1. **Single Responsibility Principle (SRP)**

**Rule**: Each class has ONE clear purpose and reason to change.

#### **âœ… Current Good Examples**:
```python
class AnthropicService:
    """Single responsibility: AI-powered search query generation"""
    def generate_pexels_query(self, model: Any) -> str:
        # Uses Claude to analyze context and generate relevant search queries
        
class PexelsService: 
    """Single responsibility: Image downloading from Pexels API"""
    def download_image(self, search_query: str, output_path: str) -> bool:
        # Handles Pexels API integration and file management
```

#### **Implementation Requirements**:
- Services handle ONE external integration each
- Domain models focus on German language validation
- Utilities provide ONE type of functionality
- Clear separation between AI services and traditional services

### 2. **Clean Architecture Layers**

**Domain â†’ Services â†’ Infrastructure** (Dependency flows inward)

```
Domain Models (Pure Python)
    â†‘ depends on
Service Layer (Business Logic) 
    â†‘ depends on  
Infrastructure (External APIs, File I/O)
```

#### **Layer Responsibilities**:
- **Domain**: German grammar rules, vocabulary validation, field processing interfaces
- **Services**: AI integration, audio/image generation, external API coordination  
- **Infrastructure**: Anki backend, file system, API clients, keyring management

### 3. **Type Safety (CRITICAL)**

**Standard**: 100% MyPy strict compliance maintained

#### **Required Practices**:
```python
# âœ… Correct: Full type annotations
def process_german_noun(noun: Noun, media_generator: MediaGenerator) -> list[str]:
    fields: list[str] = []
    enhanced_fields = noun.process_fields_for_media_generation(fields, media_generator)
    return enhanced_fields

# âŒ Wrong: Missing or weak types  
def process_noun(noun, generator):  # No type hints
    return noun.process(generator)  # Unclear return type
```

### 4. **AI-First Media Enhancement**

**Principle**: Use AI for context-aware learning materials

#### **Implementation Pattern**:
```python
class DomainModel:
    def get_image_search_terms(self) -> str:
        # 1. Try AI-enhanced context analysis first
        try:
            service = AnthropicService()
            context_query = service.generate_pexels_query(self)
            if context_query and context_query.strip():
                return context_query.strip()
        except Exception:
            pass  # Graceful degradation
            
        # 2. Fallback to concept mappings
        return self._get_fallback_terms()
```

---

## ðŸš€ Development Standards

### Code Quality Gates (MANDATORY)

Every code change MUST pass all quality gates:

```bash
# Required workflow after every change:
hatch run test                 # All tests must pass
hatch run test-cov             # Coverage maintained/improved
hatch run ruff check --fix     # Clean linting
hatch run format               # Consistent formatting  
hatch run type                 # Zero MyPy errors
```

### Testing Strategy

#### **Test Categories**:
1. **Integration Tests**: External API integration (29 tests)
2. **Domain Tests**: German grammar validation and business logic
3. **Service Tests**: AI service mocking and error handling
4. **End-to-End**: Complete deck generation workflows

#### **Coverage Requirements**:
- **Maintain**: Current 22.93% baseline
- **Improve**: Target >30% with new features
- **Focus**: Critical paths and AI integration error handling

### AI Integration Standards

#### **Claude Integration Pattern**:
```python
# âœ… Correct: Graceful degradation with fallback
def generate_context_query(self, model: WordModel) -> str:
    try:
        service = AnthropicService()
        ai_query = service.generate_pexels_query(model)
        if ai_query and ai_query.strip():
            logger.info(f"AI query: {ai_query}")
            return ai_query.strip()
    except Exception as e:
        logger.warning(f"AI query failed, using fallback: {e}")
    
    return self._fallback_query_generation(model)
```

#### **Error Handling Requirements**:
- Never fail if AI services unavailable
- Log AI usage and fallback decisions
- Validate AI responses before using
- Implement circuit breaker for repeated failures

---

## ðŸŒ Multi-Language Architecture Guidance

### Current Limitations (Multi-Language Readiness: 3/10)

#### **German-Specific Code Locations**:
```python
# âŒ Hard-coded German grammar in domain models
class Noun:
    def validate_article(self) -> bool:
        return self.article in ["der", "die", "das"]  # German-specific
        
# âŒ Template strings in code
template = "Das ist {{word}}"  # German sentence structure
```

#### **Required Refactoring for Multi-Language**:
1. **Abstract Language Service**: Extract German logic to configuration
2. **Configuration-Driven Grammar**: Move rules to external YAML/JSON files
3. **Template Externalization**: Language-specific template systems
4. **Validation Framework**: Generic rule validation with language configs

### Multi-Language Target Architecture

```python
# âœ… Target: Language-agnostic domain models
class Noun:
    def validate_grammar(self, language_service: LanguageService) -> bool:
        return language_service.validate_noun_grammar(self)

# âœ… Target: Configuration-driven templates  
class TemplateService:
    def get_template(self, language_code: str, template_type: str) -> str:
        return self.config[language_code][template_type]
```

---

## ðŸ”§ Extension Guidelines

### Adding New Parts of Speech

#### **Required Implementation Pattern**:
1. **Domain Model**: Extend from base with German grammar rules
2. **Field Processor**: Implement media enhancement interface
3. **CSV Support**: Add to vocabulary loading system
4. **AI Integration**: Include in context-aware image search
5. **Tests**: Comprehensive domain and integration testing

#### **Example Template**:
```python
@dataclass  
class Pronoun(BaseModel):
    """German pronoun with case declension."""
    
    word: str
    english: str
    example: str
    pronoun_type: PronounType
    declensions: dict[str, str]  # case -> form mapping
    
    def get_image_search_terms(self) -> str:
        # AI-first with fallback pattern
        return self._ai_enhanced_search_with_fallback()
        
    def process_fields_for_media_generation(
        self, fields: list[str], media_generator: MediaGenerator
    ) -> list[str]:
        # Standard field processing interface
        return self._process_with_media_enhancement(fields, media_generator)
```

### AI Service Extensions

#### **Adding New AI Features**:
```python
class AnthropicService:
    def generate_pexels_query(self, model: Any) -> str:
        # Existing: Context-aware image search
        
    def generate_example_sentence(self, word: str, language: str) -> str:
        # Future: AI-generated usage examples
        
    def validate_grammar_rule(self, rule: str, language: str) -> bool:
        # Future: AI grammar validation
```

---

## ðŸ“‹ Quality Maintenance

### Continuous Quality Requirements

#### **Code Quality**:
- **Type Safety**: 0 MyPy errors (strict mode)
- **Linting**: Clean ruff compliance  
- **Formatting**: Consistent code style
- **Testing**: >22% coverage maintained

#### **Architecture Quality**:
- **Separation of Concerns**: Clear layer boundaries
- **Single Responsibility**: One purpose per class
- **AI Integration**: Graceful degradation patterns
- **German Specialization**: Proper language handling

### Performance Standards

#### **AI Service Performance**:
- **Response Time**: <2 seconds for Claude queries
- **Caching**: Avoid duplicate AI calls for same content
- **Rate Limiting**: Respect API limits with backoff
- **Error Recovery**: Fast fallback to concept mappings

#### **Media Generation Performance**:
- **Image Caching**: Reuse downloaded images efficiently
- **Audio Caching**: Avoid duplicate Polly calls
- **Storage Organization**: Efficient file system structure
- **Memory Usage**: Lazy loading of large vocabulary datasets

---

## ðŸŽ¯ Strategic Direction

### Phase 1: Multi-Language Foundation (Current Priority)
- Abstract language services from German implementation
- Configuration-driven grammar rules
- Language-agnostic template system
- Validation framework for multiple languages

### Phase 2: German Language Expansion
- Additional parts of speech (pronouns, articles, conjunctions)
- Advanced grammar features (past tense, subjunctive)
- Enhanced learning features (sentence construction)
- Cultural context integration

### Phase 3: Second Language Implementation
- Validate multi-language architecture
- Create language configuration system
- Implement Spanish/French/Italian support
- Document multi-language developer workflow

---

*This guidance maintains production quality standards while enabling strategic expansion beyond German language learning.*